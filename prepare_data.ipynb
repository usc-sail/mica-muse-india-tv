{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 18,\n",
    "                     \"font.family\": \"sans-serif\",\n",
    "                     \"figure.figsize\": (20, 8),\n",
    "                     \"axes.facecolor\": \"ffffff\",\n",
    "                     \"figure.dpi\"       : 200,\n",
    "                     \"legend.fontsize\"  : \"large\",\n",
    "                     \"figure.titlesize\" : \"medium\",\n",
    "                     \"lines.linewidth\": 3,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set filenames\n",
    "video_analysis_file = \"data/[MUSE India] [RP Outputs] - Muse_India_Study_yt_local.csv.csv\"\n",
    "languages = [\"Bengali\", \"Hindi\", \"Kannada\", \"Tamil\", \"Telugu\"]\n",
    "language_analyis_files = [\n",
    "    \"data/[MUSE India] [Final] Language Analysis Results - bn.csv\",\n",
    "    \"data/[MUSE India] [Final] Language Analysis Results - hi.csv\",\n",
    "    \"data/[MUSE India] [Final] Language Analysis Results - kn.csv\",\n",
    "    \"data/[MUSE India] [Final] Language Analysis Results - ta.csv\",\n",
    "    \"data/[MUSE India] [Final] Language Analysis Results - te.csv\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the video analysis and language analysis dataframes\n",
    "video_analysis_df = pd.read_csv(video_analysis_file, index_col=None)\n",
    "language_analyis_dfs = [pd.read_csv(language_analyis_file, index_col=None) \n",
    "                        for language_analyis_file in language_analyis_files]\n",
    "language_analyis_df = pd.concat(language_analyis_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1131"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(language_analyis_df[\"Transcript word count\"] >= 100).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_analysis_df[\"key\"] = video_analysis_df[\"video_key\"]\n",
    "video_analysis_df.loc[video_analysis_df[\"key\"].isna(), \"key\"] = (\n",
    "    video_analysis_df.loc[video_analysis_df[\"key\"].isna(), \"Cat No.\"])\n",
    "language_analyis_df[\"key\"] = language_analyis_df[\"Video ID\"].str.strip(\".mp4\").str.strip(\".mov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1199, 120)\n",
      "(1186, 15)\n"
     ]
    }
   ],
   "source": [
    "print(video_analysis_df.shape)\n",
    "print(language_analyis_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1137, 120)\n",
      "(1186, 15)\n"
     ]
    }
   ],
   "source": [
    "print(video_analysis_df.drop_duplicates(\"key\", keep=False).shape)\n",
    "print(language_analyis_df.drop_duplicates(\"key\", keep=False).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "Rank\n",
      "Program name\n",
      "Channel\n",
      "Program Theme\n",
      "Program Genre\n",
      "Programme Language\n",
      "# of episodes\n",
      "rat%/AP\n",
      "Daily Avg Rch%\n",
      "Daily Avg Rch'000\n",
      "Ats(viewer)\n",
      "Program duration\n",
      "Cat No.\n",
      "YouTu.be link\n",
      "video_key\n",
      "Notes\n",
      "frames_analyzed\n",
      "(female, [0, 18), [-inf, 1.1))\n",
      "(female, [0, 18), [1.1, 2.1))\n",
      "(female, [0, 18), [2.1, 3.1))\n",
      "(female, [0, 18), [3.1, 4.1))\n",
      "(female, [0, 18), [4.1, 5.1))\n",
      "(female, [0, 18), [5.1, 6.1))\n",
      "(female, [0, 18), [6.1, 7.1))\n",
      "(female, [0, 18), [7.1, 8.1))\n",
      "(female, [0, 18), [8.1, 9.1))\n",
      "(female, [18, 33), [-inf, 1.1))\n",
      "(female, [18, 33), [1.1, 2.1))\n",
      "(female, [18, 33), [2.1, 3.1))\n",
      "(female, [18, 33), [3.1, 4.1))\n",
      "(female, [18, 33), [4.1, 5.1))\n",
      "(female, [18, 33), [5.1, 6.1))\n",
      "(female, [18, 33), [6.1, 7.1))\n",
      "(female, [18, 33), [7.1, 8.1))\n",
      "(female, [18, 33), [8.1, 9.1))\n",
      "(female, [18, 33), [9.1, 10.1))\n",
      "(female, [33, 60), [-inf, 1.1))\n",
      "(female, [33, 60), [1.1, 2.1))\n",
      "(female, [33, 60), [2.1, 3.1))\n",
      "(female, [33, 60), [3.1, 4.1))\n",
      "(female, [33, 60), [4.1, 5.1))\n",
      "(female, [33, 60), [5.1, 6.1))\n",
      "(female, [33, 60), [6.1, 7.1))\n",
      "(female, [33, 60), [7.1, 8.1))\n",
      "(female, [33, 60), [8.1, 9.1))\n",
      "(female, [33, 60), [9.1, 10.1))\n",
      "(female, [60, inf), [-inf, 1.1))\n",
      "(female, [60, inf), [1.1, 2.1))\n",
      "(female, [60, inf), [2.1, 3.1))\n",
      "(female, [60, inf), [3.1, 4.1))\n",
      "(female, [60, inf), [4.1, 5.1))\n",
      "(female, [60, inf), [5.1, 6.1))\n",
      "(female, [60, inf), [6.1, 7.1))\n",
      "(female, [60, inf), [7.1, 8.1))\n",
      "(female, [60, inf), [9.1, 10.1))\n",
      "(male, [0, 18), [-inf, 1.1))\n",
      "(male, [0, 18), [1.1, 2.1))\n",
      "(male, [0, 18), [2.1, 3.1))\n",
      "(male, [0, 18), [3.1, 4.1))\n",
      "(male, [0, 18), [4.1, 5.1))\n",
      "(male, [0, 18), [5.1, 6.1))\n",
      "(male, [0, 18), [6.1, 7.1))\n",
      "(male, [0, 18), [7.1, 8.1))\n",
      "(male, [0, 18), [8.1, 9.1))\n",
      "(male, [18, 33), [-inf, 1.1))\n",
      "(male, [18, 33), [1.1, 2.1))\n",
      "(male, [18, 33), [2.1, 3.1))\n",
      "(male, [18, 33), [3.1, 4.1))\n",
      "(male, [18, 33), [4.1, 5.1))\n",
      "(male, [18, 33), [5.1, 6.1))\n",
      "(male, [18, 33), [6.1, 7.1))\n",
      "(male, [18, 33), [7.1, 8.1))\n",
      "(male, [18, 33), [8.1, 9.1))\n",
      "(male, [18, 33), [9.1, 10.1))\n",
      "(male, [33, 60), [-inf, 1.1))\n",
      "(male, [33, 60), [1.1, 2.1))\n",
      "(male, [33, 60), [2.1, 3.1))\n",
      "(male, [33, 60), [3.1, 4.1))\n",
      "(male, [33, 60), [4.1, 5.1))\n",
      "(male, [33, 60), [5.1, 6.1))\n",
      "(male, [33, 60), [6.1, 7.1))\n",
      "(male, [33, 60), [7.1, 8.1))\n",
      "(male, [33, 60), [8.1, 9.1))\n",
      "(male, [33, 60), [9.1, 10.1))\n",
      "(male, [60, inf), [-inf, 1.1))\n",
      "(male, [60, inf), [1.1, 2.1))\n",
      "(male, [60, inf), [2.1, 3.1))\n",
      "(male, [60, inf), [3.1, 4.1))\n",
      "(male, [60, inf), [4.1, 5.1))\n",
      "(male, [60, inf), [5.1, 6.1))\n",
      "(male, [60, inf), [6.1, 7.1))\n",
      "(male, [60, inf), [7.1, 8.1))\n",
      "(male, [60, inf), [8.1, 9.1))\n",
      "(male, [60, inf), [9.1, 10.1))\n",
      "faces\n",
      "mst_scale_1\n",
      "mst_scale_2\n",
      "mst_scale_3\n",
      "mst_scale_4\n",
      "mst_scale_5\n",
      "mst_scale_6\n",
      "mst_scale_7\n",
      "mst_scale_8\n",
      "mst_scale_9\n",
      "mst_scale_10\n",
      "[0, 18)\n",
      "[18, 33)\n",
      "[33, 60)\n",
      "[60, inf)\n",
      "masculine_faces\n",
      "feminine_faces\n",
      "age_1_screen_time\n",
      "age_2_screen_time\n",
      "age_3_screen_time\n",
      "age_4_screen_time\n",
      "(female, [60, inf), [8.1, 9.1))\n",
      "(male, [0, 18), [9.1, 10.1))\n",
      "(female, [0, 18), [9.1, 10.1))\n"
     ]
    }
   ],
   "source": [
    "# print column names of the video analysis data\n",
    "for col in video_analysis_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2018: 225, 2019: 231, 2020: 250, 2021: 228, 2022: 265})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print years\n",
    "collections.Counter(video_analysis_df[\"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print number of unique program names\n",
    "video_analysis_df[\"Program name\"].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Program name\n",
       "AALTA PHORING                         [2022]\n",
       "ABHIYUM NANUM             [2020, 2021, 2022]\n",
       "ADORINI                               [2018]\n",
       "AGNISAKSHI                            [2018]\n",
       "ALO CHHAYA                            [2019]\n",
       "                                 ...        \n",
       "VISHNU PURAN                          [2020]\n",
       "YAARE NEE MOHINI          [2018, 2019, 2020]\n",
       "YAMALEELA                             [2020]\n",
       "YEH HAI CHAHATEIN                     [2022]\n",
       "ZINDAGI MERE GHAR AANA                [2022]\n",
       "Name: Year, Length: 152, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check relation between program name and year\n",
    "video_analysis_df[[\"Program name\", \"Year\"]].groupby(\"Program name\")[\"Year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print number of unique channels\n",
    "video_analysis_df[\"Channel\"].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Big Magic',\n",
       " 'Colors',\n",
       " 'Colors Kannada',\n",
       " 'Colors Rishtey',\n",
       " 'DD Bharati',\n",
       " 'DD National',\n",
       " 'Dangal',\n",
       " 'Dangal/DD National',\n",
       " 'ETV Telugu',\n",
       " 'STAR Jalsha',\n",
       " 'STAR Maa',\n",
       " 'STAR Plus',\n",
       " 'STAR Utsav',\n",
       " 'STAR Vijay',\n",
       " 'Shemaroo TV',\n",
       " 'Sony Pal',\n",
       " 'Sun TV',\n",
       " 'Udaya TV',\n",
       " 'Zee Anmol',\n",
       " 'Zee Bangla',\n",
       " 'Zee Kannada',\n",
       " 'Zee TV',\n",
       " 'Zee TV/Zee Anmol',\n",
       " 'Zee Tamil',\n",
       " 'Zee Telugu']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the unique channels\n",
    "sorted(video_analysis_df[\"Channel\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Program name\n",
       "RAMAYAN      [Dangal, Dangal/DD National]\n",
       "TRINAYANI        [Zee Bangla, Zee Telugu]\n",
       "Name: Channel, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print program names broadcast in more than one channel\n",
    "df = video_analysis_df[[\"Program name\", \"Channel\"]].groupby(\"Program name\")[\"Channel\"].unique()\n",
    "df[df.apply(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'DRAMA/SOAP': 1115,\n",
       "         'ACTION/THRILLER': 10,\n",
       "         'MYTHOLOGICAL/COSTUME DRAMAS': 69,\n",
       "         'CHILDRENS PROGRAM': 5})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print distribution of program themes\n",
    "collections.Counter(video_analysis_df[\"Program Theme\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check correspondence between program name and program theme\n",
    "video_analysis_df[[\"Program name\", \"Program Theme\"]].groupby(\"Program name\")[\"Program Theme\"].unique().apply(len).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Program name\n",
       "TRINAYANI    [BENGALI, TELUGU]\n",
       "Name: Programme Language, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print program names broadcast in more than one language\n",
    "df = video_analysis_df[[\"Program name\", \"Programme Language\"]].groupby(\"Program name\")[\"Programme Language\"].unique()\n",
    "df[df.apply(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year  Programme Language\n",
       "2018  BENGALI               35\n",
       "      HINDI                 47\n",
       "      KANNADA               49\n",
       "      TAMIL                 45\n",
       "      TELUGU                49\n",
       "2019  BENGALI               36\n",
       "      HINDI                 50\n",
       "      KANNADA               45\n",
       "      TAMIL                 50\n",
       "      TELUGU                50\n",
       "2020  BENGALI               41\n",
       "      HINDI                 65\n",
       "      KANNADA               50\n",
       "      TAMIL                 45\n",
       "      TELUGU                49\n",
       "2021  BENGALI               49\n",
       "      HINDI                 50\n",
       "      KANNADA               49\n",
       "      TAMIL                 50\n",
       "      TELUGU                30\n",
       "2022  BENGALI               69\n",
       "      HINDI                 56\n",
       "      KANNADA               39\n",
       "      TAMIL                 50\n",
       "      TELUGU                51\n",
       "Name: Program name, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print number of videos per year per language\n",
    "video_analysis_df.groupby([\"Year\", \"Programme Language\"]).count()[\"Program name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rat%/AP</th>\n",
       "      <th>Daily Avg Rch%</th>\n",
       "      <th>Ats(viewer)</th>\n",
       "      <th>Program duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.48</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0:14:50</td>\n",
       "      <td>0:29:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.48</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0:14:50</td>\n",
       "      <td>0:29:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.48</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0:14:50</td>\n",
       "      <td>0:29:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.48</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0:14:50</td>\n",
       "      <td>0:29:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.48</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0:14:50</td>\n",
       "      <td>0:29:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>5.20</td>\n",
       "      <td>8.68</td>\n",
       "      <td>0:18:00</td>\n",
       "      <td>0:30:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>5.20</td>\n",
       "      <td>8.68</td>\n",
       "      <td>0:18:00</td>\n",
       "      <td>0:30:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>5.20</td>\n",
       "      <td>8.68</td>\n",
       "      <td>0:18:00</td>\n",
       "      <td>0:30:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>5.20</td>\n",
       "      <td>8.68</td>\n",
       "      <td>0:18:00</td>\n",
       "      <td>0:30:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>5.20</td>\n",
       "      <td>8.68</td>\n",
       "      <td>0:18:00</td>\n",
       "      <td>0:30:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rat%/AP  Daily Avg Rch% Ats(viewer) Program duration\n",
       "0        2.48            5.00     0:14:50          0:29:52\n",
       "1        2.48            5.00     0:14:50          0:29:52\n",
       "2        2.48            5.00     0:14:50          0:29:52\n",
       "3        2.48            5.00     0:14:50          0:29:52\n",
       "4        2.48            5.00     0:14:50          0:29:52\n",
       "...       ...             ...         ...              ...\n",
       "1194     5.20            8.68     0:18:00          0:30:02\n",
       "1195     5.20            8.68     0:18:00          0:30:02\n",
       "1196     5.20            8.68     0:18:00          0:30:02\n",
       "1197     5.20            8.68     0:18:00          0:30:02\n",
       "1198     5.20            8.68     0:18:00          0:30:02\n",
       "\n",
       "[1199 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print ratings vars\n",
    "video_analysis_df[[\"rat%/AP\", \"Daily Avg Rch%\", \"Ats(viewer)\", \"Program duration\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ats(viewer)</th>\n",
       "      <th>Program duration</th>\n",
       "      <th>Ats(viewer)(sec)</th>\n",
       "      <th>Program duration(sec)</th>\n",
       "      <th>Ats(viewer)%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0:14:50</td>\n",
       "      <td>0:29:52</td>\n",
       "      <td>890</td>\n",
       "      <td>1792</td>\n",
       "      <td>49.665179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0:14:50</td>\n",
       "      <td>0:29:52</td>\n",
       "      <td>890</td>\n",
       "      <td>1792</td>\n",
       "      <td>49.665179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0:14:50</td>\n",
       "      <td>0:29:52</td>\n",
       "      <td>890</td>\n",
       "      <td>1792</td>\n",
       "      <td>49.665179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0:14:50</td>\n",
       "      <td>0:29:52</td>\n",
       "      <td>890</td>\n",
       "      <td>1792</td>\n",
       "      <td>49.665179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0:14:50</td>\n",
       "      <td>0:29:52</td>\n",
       "      <td>890</td>\n",
       "      <td>1792</td>\n",
       "      <td>49.665179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>0:18:00</td>\n",
       "      <td>0:30:02</td>\n",
       "      <td>1080</td>\n",
       "      <td>1802</td>\n",
       "      <td>59.933407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>0:18:00</td>\n",
       "      <td>0:30:02</td>\n",
       "      <td>1080</td>\n",
       "      <td>1802</td>\n",
       "      <td>59.933407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>0:18:00</td>\n",
       "      <td>0:30:02</td>\n",
       "      <td>1080</td>\n",
       "      <td>1802</td>\n",
       "      <td>59.933407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>0:18:00</td>\n",
       "      <td>0:30:02</td>\n",
       "      <td>1080</td>\n",
       "      <td>1802</td>\n",
       "      <td>59.933407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>0:18:00</td>\n",
       "      <td>0:30:02</td>\n",
       "      <td>1080</td>\n",
       "      <td>1802</td>\n",
       "      <td>59.933407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ats(viewer) Program duration  Ats(viewer)(sec)  Program duration(sec)  \\\n",
       "0        0:14:50          0:29:52               890                   1792   \n",
       "1        0:14:50          0:29:52               890                   1792   \n",
       "2        0:14:50          0:29:52               890                   1792   \n",
       "3        0:14:50          0:29:52               890                   1792   \n",
       "4        0:14:50          0:29:52               890                   1792   \n",
       "...          ...              ...               ...                    ...   \n",
       "1194     0:18:00          0:30:02              1080                   1802   \n",
       "1195     0:18:00          0:30:02              1080                   1802   \n",
       "1196     0:18:00          0:30:02              1080                   1802   \n",
       "1197     0:18:00          0:30:02              1080                   1802   \n",
       "1198     0:18:00          0:30:02              1080                   1802   \n",
       "\n",
       "      Ats(viewer)%  \n",
       "0        49.665179  \n",
       "1        49.665179  \n",
       "2        49.665179  \n",
       "3        49.665179  \n",
       "4        49.665179  \n",
       "...            ...  \n",
       "1194     59.933407  \n",
       "1195     59.933407  \n",
       "1196     59.933407  \n",
       "1197     59.933407  \n",
       "1198     59.933407  \n",
       "\n",
       "[1199 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get average time percentage\n",
    "def parse_duration(x):\n",
    "    h, m, s = x.split(\":\")\n",
    "    h, m, s = int(h), int(m), int(s)\n",
    "    duration = 3600*h + 60*m + s\n",
    "    return duration\n",
    "\n",
    "video_analysis_df[\"Ats(viewer)(sec)\"] = video_analysis_df[\"Ats(viewer)\"].apply(lambda x: parse_duration(x))\n",
    "video_analysis_df[\"Program duration(sec)\"] = video_analysis_df[\"Program duration\"].apply(lambda x: parse_duration(x))\n",
    "video_analysis_df[\"Ats(viewer)%\"] = (\n",
    "    100 * video_analysis_df[\"Ats(viewer)(sec)\"]/video_analysis_df[\"Program duration(sec)\"])\n",
    "video_analysis_df[[\"Ats(viewer)\", \"Program duration\", \"Ats(viewer)(sec)\", \"Program duration(sec)\", \"Ats(viewer)%\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create faces data\n",
    "# n_faces_arr[i, j, k, l] = number of faces of gender j and age k and skintone l in video i\n",
    "gender_cats = [\"male\", \"female\"]\n",
    "age_cats = [\"[0, 18)\", \"[18, 33)\", \"[33, 60)\", \"[60, inf)\"]\n",
    "skintone_cats = [\"[-inf, 1.1)\", \"[1.1, 2.1)\", \"[2.1, 3.1)\", \"[3.1, 4.1)\", \"[4.1, 5.1)\", \"[5.1, 6.1)\", \"[6.1, 7.1)\",\n",
    "                 \"[7.1, 8.1)\", \"[8.1, 9.1)\", \"[9.1, 10.1)\"]\n",
    "n_faces_arr = np.zeros((len(video_analysis_df), len(gender_cats), len(age_cats), len(skintone_cats)), dtype=int)\n",
    "\n",
    "for index, row in video_analysis_df.iterrows():\n",
    "    for i, gender_cat in enumerate(gender_cats):\n",
    "        for j, age_cat in enumerate(age_cats):\n",
    "            for k, skintone_cat in enumerate(skintone_cats):\n",
    "                cat = f\"({gender_cat}, {age_cat}, {skintone_cat})\"\n",
    "                if cat in row and pd.notna(row[cat]):\n",
    "                    n_faces_arr[index, i, j, k] = row[cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the number of faces for gender, age, and skintone is consistent\n",
    "for index, row in video_analysis_df.iterrows():\n",
    "    assert n_faces_arr[index].sum() == row[\"faces\"]\n",
    "    assert all(n_faces_arr[index].sum(axis=(1, 2)) == row[[\"masculine_faces\", \"feminine_faces\"]].tolist())\n",
    "    assert all(n_faces_arr[index].sum(axis=(0, 2)) == row[age_cats].tolist())\n",
    "    assert all(n_faces_arr[index].sum(axis=(0, 1)) == row[[f\"mst_scale_{i}\" for i in range(1, 11)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create video id column\n",
    "video_analysis_df[\"Video ID\"] = video_analysis_df[\"video_key\"]\n",
    "video_analysis_df.loc[video_analysis_df[\"Video ID\"].isna(), \"Video ID\"] = (\n",
    "    video_analysis_df.loc[video_analysis_df[\"Video ID\"].isna(), \"Cat No.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create metadata df of video id, video key, year, program name, genre, channel, ats, ratings, reach and language\n",
    "metadata_df = video_analysis_df[[\"Video ID\", \"Year\", \"Program name\", \"Programme Language\", \"Program Theme\", \"Channel\", \n",
    "                                 \"Ats(viewer)%\", \"rat%/AP\", \"Daily Avg Rch%\"]].copy()\n",
    "metadata_df.columns = [\"video_id\", \"year\", \"program\", \"lang\", \"genre\", \"channel\", \"ats\", \"rating\", \"reach\"]\n",
    "metadata_df[\"video_key\"] = np.arange(len(video_analysis_df))\n",
    "metadata_df = metadata_df[[\"video_key\", \"video_id\", \"program\", \"year\", \"lang\", \"genre\", \"channel\", \n",
    "                           \"ats\", \"rating\", \"reach\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create metadata and video analysis dataframe in wide and long forms\n",
    "# columns are video_key, program name, year, lang, gender, age, skintone, number of faces\n",
    "# each video_key will have 2 x 4 x 3 rows = 24 rows\n",
    "long_data_rows = []\n",
    "wide_data_rows = []\n",
    "named_age_cats = [\"young\", \"adult\", \"middle_aged\", \"old\"]\n",
    "named_skintone_cats = [\"light\", \"medium\", \"dark\"]\n",
    "\n",
    "for index, row in metadata_df.iterrows():\n",
    "    total_faces = n_faces_arr[index].sum()\n",
    "\n",
    "    for i, gender_cat in enumerate(gender_cats):\n",
    "        for j, age_cat in enumerate(named_age_cats):\n",
    "            for skintone_cat in named_skintone_cats:\n",
    "                if skintone_cat == \"light\":\n",
    "                    k1, k2 = 0, 3\n",
    "                elif skintone_cat == \"medium\":\n",
    "                    k1, k2 = 3, 6\n",
    "                else:\n",
    "                    k1, k2 = 6, 10\n",
    "                faces = n_faces_arr[index, i, j, k1 : k2].sum()\n",
    "                long_data_rows.append(row.tolist() + [gender_cat, age_cat, skintone_cat, faces])\n",
    "    \n",
    "    gender_faces = n_faces_arr[index].sum(axis=(1, 2)).tolist()\n",
    "    age_faces = n_faces_arr[index].sum(axis=(0, 2)).tolist()\n",
    "    skintone_faces = n_faces_arr[index].sum(axis=(0, 1))\n",
    "    skintone_faces = [skintone_faces[:3].sum(), skintone_faces[3:6].sum(), skintone_faces[6:].sum()]\n",
    "    wide_data_rows.append(row.tolist() + gender_faces + age_faces + skintone_faces + [total_faces])\n",
    "\n",
    "long_data_df = pd.DataFrame(long_data_rows, columns=metadata_df.columns.tolist() \n",
    "                            + [\"gender\", \"age\", \"skintone\", \"faces\"])\n",
    "long_data_df.to_csv(\"video_only_long_form.csv\", index=False)\n",
    "\n",
    "wide_data_df = pd.DataFrame(wide_data_rows, columns=metadata_df.columns.tolist()\n",
    "                            + [\"male_faces\", \"female_faces\", \"young_faces\", \"adult_faces\", \"middle_aged_faces\",\n",
    "                               \"old_faces\", \"light_faces\", \"medium_faces\", \"dark_faces\", \"faces\"])\n",
    "wide_data_df.to_csv(\"video_only_wide_form.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language\n",
      "Video ID\n",
      "Controversial Topics (LLM)\n",
      "Derogatory Words (LLM)\n",
      "Derogatory Words (dictionary)\n",
      "Person names\n",
      "Transcript word count\n",
      "Transcript unique word count\n",
      "Transcript non-stopword count\n",
      "Transcript unique non-stop word count\n",
      "Derogatory words (dictionary) word count\n",
      "Derogatory words (LLM) word count\n",
      "Controversial topics (LLM) word count\n",
      "Person names word count\n"
     ]
    }
   ],
   "source": [
    "# print language analysis column\n",
    "for col in language_analyis_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168 video ids, 1186 lang ids\n",
      "975\n"
     ]
    }
   ],
   "source": [
    "# number of common keys between language analysis and video analysis dataframes\n",
    "lang_ids = set(language_analyis_df[\"Video ID\"].tolist())\n",
    "video_ids = set(video_analysis_df[\"Video ID\"].tolist())\n",
    "print(f\"{len(video_ids)} video ids, {len(lang_ids)} lang ids\")\n",
    "print(len(video_ids.intersection(lang_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'hindu': 14250, 'muslim': 96, 'christian': 57, 'unknown': 25})\n",
      "Counter({'male': 7851, 'female': 5950, 'unknown': 389, 'unisex': 238})\n"
     ]
    }
   ],
   "source": [
    "# print distribution of religions and genders\n",
    "religions = []\n",
    "genders = []\n",
    "\n",
    "for person_names_list_str in language_analyis_df[\"Person names word count\"]:\n",
    "    person_names_list = re.findall(r\"\\([^\\)]+\\)\", person_names_list_str)\n",
    "    for person_name_tuple_str in person_names_list:\n",
    "        person_name_tuple = person_name_tuple_str[1:-1].split(\", \")\n",
    "        religions.append(person_name_tuple[1].strip(\"'\"))\n",
    "        genders.append(person_name_tuple[2].strip(\"'\"))\n",
    "\n",
    "print(collections.Counter(religions))\n",
    "print(collections.Counter(genders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bn', 'hi', 'kn', 'ta', 'te'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_analyis_df[\"Language\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create language wide form\n",
    "rows = []\n",
    "header = [\"video_id\", \"lang\", \"derogatory\", \"controversial\", \n",
    "          \"male_person_name\", \"female_person_name\", \"unisex_person_name\",\n",
    "          \"hindu_person_name\", \"muslim_person_name\", \"christian_person_name\",\n",
    "          \"transcript\", \"non_stopword_transcript\"]\n",
    "\n",
    "for _, row in language_analyis_df.iterrows():\n",
    "    video_id = row[\"Video ID\"]\n",
    "    lang = row[\"Language\"]\n",
    "\n",
    "    if lang == \"bn\":\n",
    "        lang = \"BENGALI\"\n",
    "    elif lang == \"hi\":\n",
    "        lang = \"HINDI\"\n",
    "    elif lang == \"kn\":\n",
    "        lang = \"KANNADA\"\n",
    "    elif lang == \"ta\":\n",
    "        lang = \"TAMIL\"\n",
    "    elif lang == \"te\":\n",
    "        lang = \"TELUGU\"\n",
    "\n",
    "    # derogatory words\n",
    "    derogatory_count_str = row[\"Derogatory words (dictionary) word count\"]\n",
    "    if derogatory_count_str != \"None\":\n",
    "        derogatory_tuples_str = re.findall(r\"\\([^\\)]+\\)\", derogatory_count_str[1:-1])\n",
    "        derogatory_count = sum([int(tup[1:-1].split(\", \")[1]) for tup in derogatory_tuples_str])\n",
    "    else:\n",
    "        derogatory_count = 0\n",
    "\n",
    "    # controversial count\n",
    "    controversial_count_str = row[\"Controversial topics (LLM) word count\"]\n",
    "    if controversial_count_str != \"None\":\n",
    "        controversial_tuples_str = re.findall(r\"\\([^\\)]+\\)\", controversial_count_str[1:-1])\n",
    "        controversial_count = sum([int(tup[1:-1].split(\", \")[1]) for tup in controversial_tuples_str])\n",
    "    else:\n",
    "        controversial_count = 0\n",
    "\n",
    "    # person name count\n",
    "    religions = []\n",
    "    genders = []\n",
    "    person_name_str = row[\"Person names word count\"]\n",
    "    person_names_list = re.findall(r\"\\([^\\)]+\\)\", person_name_str)\n",
    "    for person_name_tuple_str in person_names_list:\n",
    "        person_name_tuple = person_name_tuple_str[1:-1].split(\", \")\n",
    "        religions.append(person_name_tuple[1].strip(\"'\"))\n",
    "        genders.append(person_name_tuple[2].strip(\"'\"))\n",
    "    religion_dict = collections.Counter(religions)\n",
    "    gender_dict = collections.Counter(genders)\n",
    "    \n",
    "    hindu_count = religion_dict.get(\"hindu\", 0)\n",
    "    muslim_count = religion_dict.get(\"muslim\", 0)\n",
    "    christian_count = religion_dict.get(\"christian\", 0)\n",
    "    male_count = gender_dict.get(\"male\", 0)\n",
    "    female_count = gender_dict.get(\"female\", 0)\n",
    "    person_name_count = len(person_names_list)\n",
    "\n",
    "    # transcript count\n",
    "    transcript_count = row[\"Transcript word count\"]\n",
    "    nonstopword_transcript_count = row[\"Transcript non-stopword count\"]\n",
    "\n",
    "    # create wide-form row\n",
    "    rows.append([video_id, lang, derogatory_count, controversial_count, person_name_count,\n",
    "                 hindu_count, muslim_count, christian_count, male_count, female_count,\n",
    "                 transcript_count, nonstopword_transcript_count])\n",
    "\n",
    "lang_wide_df = pd.DataFrame(rows, columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_wide_df = (lang_wide_df\n",
    "                .merge(wide_data_df[[\"video_id\", \"program\", \"year\", \"lang\", \"genre\", \"channel\", \"ats\",\"rating\",\n",
    "                                     \"reach\"]]\n",
    "                .drop_duplicates(\"video_id\", keep=False), \n",
    "                how=\"left\", on=[\"video_id\", \"lang\"], suffixes=(\"_vd\", \"_ln\"))\n",
    "                .dropna())\n",
    "lang_wide_df.to_csv(\"lang_only_wide_form.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create video-language wide form\n",
    "wide_data_nodup_df = wide_data_df.drop_duplicates(\"video_id\", keep=False).copy()\n",
    "video_lang_wide_df =  wide_data_nodup_df.merge(lang_wide_df, how=\"inner\", on=[\"video_id\", \"lang\"], \n",
    "                                               suffixes=(\"_vd\", \"_ln\"))\n",
    "video_lang_wide_df.to_csv(\"video_lang_wide_form.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>derogatory</th>\n",
       "      <th>controversial</th>\n",
       "      <th>male_person_name</th>\n",
       "      <th>female_person_name</th>\n",
       "      <th>unisex_person_name</th>\n",
       "      <th>hindu_person_name</th>\n",
       "      <th>muslim_person_name</th>\n",
       "      <th>christian_person_name</th>\n",
       "      <th>transcript</th>\n",
       "      <th>non_stopword_transcript</th>\n",
       "      <th>program</th>\n",
       "      <th>year</th>\n",
       "      <th>genre</th>\n",
       "      <th>channel</th>\n",
       "      <th>ats</th>\n",
       "      <th>rating</th>\n",
       "      <th>reach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-PUpZlgFVlI</td>\n",
       "      <td>BENGALI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>GAATCHORA</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>DRAMA/SOAP</td>\n",
       "      <td>STAR Jalsha</td>\n",
       "      <td>59.477562</td>\n",
       "      <td>2.60</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-R6Iou8twaw</td>\n",
       "      <td>BENGALI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>GAATCHORA</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>DRAMA/SOAP</td>\n",
       "      <td>STAR Jalsha</td>\n",
       "      <td>59.477562</td>\n",
       "      <td>2.60</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-Y9oaa82Vxw</td>\n",
       "      <td>BENGALI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1626</td>\n",
       "      <td>855</td>\n",
       "      <td>JOY BABA LOKENATH</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>DRAMA/SOAP</td>\n",
       "      <td>Zee Bangla</td>\n",
       "      <td>48.152296</td>\n",
       "      <td>3.93</td>\n",
       "      <td>8.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0B1QD63DzOc</td>\n",
       "      <td>BENGALI</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1840</td>\n",
       "      <td>1077</td>\n",
       "      <td>KHUKUMONI HOME DELIVERY</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>DRAMA/SOAP</td>\n",
       "      <td>STAR Jalsha</td>\n",
       "      <td>62.888889</td>\n",
       "      <td>3.97</td>\n",
       "      <td>6.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0qUmRtgLuPY</td>\n",
       "      <td>BENGALI</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1649</td>\n",
       "      <td>888</td>\n",
       "      <td>TRINAYANI</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>DRAMA/SOAP</td>\n",
       "      <td>Zee Bangla</td>\n",
       "      <td>57.865481</td>\n",
       "      <td>2.86</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>yk8GpevC7eU</td>\n",
       "      <td>TELUGU</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1153</td>\n",
       "      <td>720</td>\n",
       "      <td>THAT IS MAHALAKSHMI</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>DRAMA/SOAP</td>\n",
       "      <td>Zee Telugu</td>\n",
       "      <td>51.798561</td>\n",
       "      <td>6.05</td>\n",
       "      <td>11.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>yrcoJULwm9A</td>\n",
       "      <td>TELUGU</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1626</td>\n",
       "      <td>1147</td>\n",
       "      <td>NAA PERU MEENAKSHI</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>DRAMA/SOAP</td>\n",
       "      <td>ETV Telugu</td>\n",
       "      <td>46.944444</td>\n",
       "      <td>4.62</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>yzfIeSk5t3k</td>\n",
       "      <td>TELUGU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1360</td>\n",
       "      <td>834</td>\n",
       "      <td>PREMA ENTHA MADHURAM</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>DRAMA/SOAP</td>\n",
       "      <td>Zee Telugu</td>\n",
       "      <td>57.592490</td>\n",
       "      <td>5.95</td>\n",
       "      <td>10.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>zCXLrTSX910</td>\n",
       "      <td>TELUGU</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1248</td>\n",
       "      <td>840</td>\n",
       "      <td>THAT IS MAHALAKSHMI</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>DRAMA/SOAP</td>\n",
       "      <td>Zee Telugu</td>\n",
       "      <td>51.798561</td>\n",
       "      <td>6.05</td>\n",
       "      <td>11.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>zu4qOsy3afU</td>\n",
       "      <td>TELUGU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1422</td>\n",
       "      <td>959</td>\n",
       "      <td>GORINTAKU</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>DRAMA/SOAP</td>\n",
       "      <td>STAR Maa</td>\n",
       "      <td>53.540904</td>\n",
       "      <td>4.81</td>\n",
       "      <td>8.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>939 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id     lang  derogatory  controversial  male_person_name  \\\n",
       "0     -PUpZlgFVlI  BENGALI           0              0                 4   \n",
       "1     -R6Iou8twaw  BENGALI           0              0                 7   \n",
       "2     -Y9oaa82Vxw  BENGALI           0              0                12   \n",
       "3     0B1QD63DzOc  BENGALI           3              0                 0   \n",
       "4     0qUmRtgLuPY  BENGALI           1              0                 0   \n",
       "...           ...      ...         ...            ...               ...   \n",
       "1086  yk8GpevC7eU   TELUGU           2              0                 9   \n",
       "1087  yrcoJULwm9A   TELUGU           1              0                 9   \n",
       "1088  yzfIeSk5t3k   TELUGU           0              0                 9   \n",
       "1089  zCXLrTSX910   TELUGU           1              0                10   \n",
       "1090  zu4qOsy3afU   TELUGU           0              0                13   \n",
       "\n",
       "      female_person_name  unisex_person_name  hindu_person_name  \\\n",
       "0                      4                   0                  0   \n",
       "1                      7                   0                  0   \n",
       "2                     11                   1                  0   \n",
       "3                      0                   0                  0   \n",
       "4                      0                   0                  0   \n",
       "...                  ...                 ...                ...   \n",
       "1086                   8                   0                  1   \n",
       "1087                   9                   0                  0   \n",
       "1088                   9                   0                  0   \n",
       "1089                  10                   0                  0   \n",
       "1090                  12                   0                  1   \n",
       "\n",
       "      muslim_person_name  christian_person_name  transcript  \\\n",
       "0                      2                      2          36   \n",
       "1                      7                      0          16   \n",
       "2                      8                      4        1626   \n",
       "3                      0                      0        1840   \n",
       "4                      0                      0        1649   \n",
       "...                  ...                    ...         ...   \n",
       "1086                   3                      6        1153   \n",
       "1087                   5                      4        1626   \n",
       "1088                   6                      3        1360   \n",
       "1089                   4                      6        1248   \n",
       "1090                   8                      5        1422   \n",
       "\n",
       "      non_stopword_transcript                  program    year       genre  \\\n",
       "0                           9                GAATCHORA  2022.0  DRAMA/SOAP   \n",
       "1                           5                GAATCHORA  2022.0  DRAMA/SOAP   \n",
       "2                         855        JOY BABA LOKENATH  2018.0  DRAMA/SOAP   \n",
       "3                        1077  KHUKUMONI HOME DELIVERY  2021.0  DRAMA/SOAP   \n",
       "4                         888                TRINAYANI  2019.0  DRAMA/SOAP   \n",
       "...                       ...                      ...     ...         ...   \n",
       "1086                      720      THAT IS MAHALAKSHMI  2018.0  DRAMA/SOAP   \n",
       "1087                     1147       NAA PERU MEENAKSHI  2019.0  DRAMA/SOAP   \n",
       "1088                      834     PREMA ENTHA MADHURAM  2020.0  DRAMA/SOAP   \n",
       "1089                      840      THAT IS MAHALAKSHMI  2018.0  DRAMA/SOAP   \n",
       "1090                      959                GORINTAKU  2019.0  DRAMA/SOAP   \n",
       "\n",
       "          channel        ats  rating  reach  \n",
       "0     STAR Jalsha  59.477562    2.60   4.37  \n",
       "1     STAR Jalsha  59.477562    2.60   4.37  \n",
       "2      Zee Bangla  48.152296    3.93   8.17  \n",
       "3     STAR Jalsha  62.888889    3.97   6.31  \n",
       "4      Zee Bangla  57.865481    2.86   4.94  \n",
       "...           ...        ...     ...    ...  \n",
       "1086   Zee Telugu  51.798561    6.05  11.68  \n",
       "1087   ETV Telugu  46.944444    4.62   9.84  \n",
       "1088   Zee Telugu  57.592490    5.95  10.34  \n",
       "1089   Zee Telugu  51.798561    6.05  11.68  \n",
       "1090     STAR Maa  53.540904    4.81   8.97  \n",
       "\n",
       "[939 rows x 19 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_wide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create language long form for religious person names\n",
    "\n",
    "rows = []\n",
    "\n",
    "for _, row in lang_wide_df.iterrows():\n",
    "    for religion in [\"hindu\", \"muslim\", \"christian\"]:\n",
    "        person_name_count = row[f\"{religion}_person_name\"]\n",
    "        rows.append(row.tolist() + [religion, person_name_count])\n",
    "\n",
    "lang_religion_long_df = pd.DataFrame(rows, columns=lang_wide_df.columns.tolist() + [\"religion\", \"person_name_count\"])\n",
    "lang_religion_long_df.drop(columns=[\"hindu_person_name\", \"muslim_person_name\", \"christian_person_name\"], inplace=False)\n",
    "lang_religion_long_df.to_csv(\"lang_only_religion_long_form.csv\", index=False)\n",
    "\n",
    "# create language long form for gendered person names\n",
    "\n",
    "rows = []\n",
    "\n",
    "for _, row in lang_wide_df.iterrows():\n",
    "    for gender in [\"male\", \"female\"]:\n",
    "        person_name_count = row[f\"{gender}_person_name\"]\n",
    "        rows.append(row.tolist() + [gender, person_name_count])\n",
    "\n",
    "lang_gender_long_df = pd.DataFrame(rows, columns=lang_wide_df.columns.tolist() + [\"gender\", \"person_name_count\"])\n",
    "lang_gender_long_df.drop(columns=[\"male_person_name\", \"female_person_name\"], inplace=False)\n",
    "lang_gender_long_df.to_csv(\"lang_only_gender_long_form.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coreference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
